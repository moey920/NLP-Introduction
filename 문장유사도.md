# 문장 유사도

> 문장 간 유사도는 **공통된 단어** 혹은 **의미**를 기반으로 계산

```
[문장 1] : 오늘은 중부지방을 중심으로 소나기가 예상됩니다.
[문장 2] : 오늘은 전국이 맑은 날씨가 예상됩니다.
[문장 3] : 앞으로 접종 속도는 빨라질 것으로 예상됩니다.
```

## 자카드 지수

- 자카드(Jaccard) 지수는 문장 간 공통된 단어의 비율로 문장 간 유사도를 정의
    - 자카드 지수는 문장 간 유사도를 0 ~ 1 사이로 정의
    - 단어 기준으로만 정의하기 때문에 의미적인 내용을 판단할 수 없는 단점을 가지고 있다. 하지만 빠르고 쉬운 것이 장점이다.

`문장 1과 문장 2의 유사도 = (두 문장 내 공통된 단어의 종류) / (두 문장 내 모든 단어의 종류)`  

```
[문장 1] : '오늘은' 중부지방을 중심으로 소나기가 '예상됩니다'.
[문장 2] : '오늘은' 전국이 맑은 날씨가 '예상됩니다'.
문장 1과 문장 2의 유사도 = 2/8 = 0.25
```

## 코사인 유사도

- **코사인 유사도**는 문장 벡터 간의 각도를 기반으로 계산
- 문장을 벡터로 변환한다.
    - 벡터 간의 각도는 벡터 간 내적을 사용해서 계산
    - 각도가 작을수록 비슷한 문장이다.
- 나이브 베이즈 기반에서 smilarty를 계산했을 때 사용한 단어 벡터간 유사도도 코사인 유사도 기반이다.
    ```
    A = [1, 3], B = [0 ,2]
    A와 B의 코사인 유사도 = A∙B / ||𝐴||||B||  = (1 × 0) + (3 × 2) / root(1^2+3^2) * root(0^2 + 2^2) = 6 / 2root(10) ≈ 0.9487
    ```
- 유클리드 거리와 같은 다양한 거리 지표가 존재
- 코사인 유사도는 **고차원의 공간에서 벡터 간의 유사성을 잘 보존하는 장점**이 있음
    - `d(p, q) = root(sum((qi-pi)^2))`
    - 문서를 모두 임베딩 벡터, 벡터화하기 때문에 길이가 매우 길다(매우 고차원에 존재한다.) -> 유클리드 거리보다는 각 벡터간의 각도를 사용하는 코사인 유사도가 훨씬 정보를 잘 보존한다.
    - 문장, 단어 유사도 모두 코사인 유사도를 사용하는 것이 권장된다.
